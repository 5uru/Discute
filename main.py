import os
import io
import tempfile
from typing import Optional

import whisper
import torchaudio
from kokoro import KPipeline
from langchain.chat_models import init_chat_model


def transcribe_audio(audio_data: bytes) -> str:
    """
    Transcribe audio data to text.

    Args:
        audio_data: Audio data in bytes format

    Returns:
        Transcribed text or error message
    """
    temp_audio_path = None
    try:
        # Create a temporary file to store audio data
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as temp_audio:
            temp_audio.write(audio_data)
            temp_audio_path = temp_audio.name

        # Load Whisper model and transcribe audio
        model = whisper.load_model("base.en")  # or any other model size
        result = model.transcribe(temp_audio_path)

        return result["text"]

    except Exception as e:
        return f"Transcription error: {str(e)}"

    finally:
        # Ensure a temporary file is deleted even if an error occurs
        if temp_audio_path and os.path.exists(temp_audio_path):
            os.unlink(temp_audio_path)


def generate_response(prompt: str, model_name: str, groq_api_key: str) -> str:
    """
    Generate a response from a prompt using a language model.

    Args:
        prompt: Input text for the model
        model_name: Name of the model to use
        groq_api_key: API key for Groq

    Returns:
        Response generated by the model
    """
    try:
        # Set API key
        os.environ["GROQ_API_KEY"] = groq_api_key

        # Initialize and invoke the model
        model = init_chat_model(model_name, model_provider="groq")
        response = model.invoke(prompt)

        return response.content if response else "No response generated."

    except Exception as e:
        return f"Error generating response: {str(e)}"


def generate_audio(text: str, voice: str) -> Optional[bytes]:
    """
    Generate an audio file from a text.

    Args:
        text: Text to convert to audio
        voice: Voice to use for generation

    Returns:
        Audio data in byte format or None of error
    """
    try:
        # Clean text to avoid segmentation issues
        text = text.replace('\n', ' ')

        # Initialize audio generation pipeline
        pipeline = KPipeline(lang_code='a')

        # Generate audio
        generator = pipeline(
                text,
                voice=voice,  # Change voice here
                speed=1,
                split_pattern=r'\n+'
        )

        # Take the first generated result
        for _, _, audio in generator:
            # Convert tensor to bytes
            buffer = io.BytesIO()
            torchaudio.save(buffer, audio.unsqueeze(0), sample_rate=24000, format="wav")
            buffer.seek(0)
            return buffer.read()

        return None

    except Exception as e:
        print(f"Error generating audio: {str(e)}")
        return None